# Counterfactual Data Augmentation (CDA) Pipeline
 
> For detailed pipeline usage and fine-tuning instructions, see [`main/README.md`](main/README.md).

## ğŸ“ Repository Structure

```text
.
â”œâ”€â”€ data/                      # All pipeline inputs and outputsâ”‚
â”œâ”€â”€ main/                     # Core pipeline implementation
â”‚   â”œâ”€â”€ bash_scripts/        # Execution scripts
â”‚   â””â”€â”€ README.md            # Detailed instructions
â”‚
â”œâ”€â”€ human_annotation_data/    # Validation datasets
â”œâ”€â”€ data_utils/              # Analysis utilities
â””â”€â”€ llm_evaluation_data/     # LLM evaluation results
```

## ğŸš€ Quick Start

1. **Core Components**: Only `data/` and `main/` directories are required to run the pipeline
2. **Setup Instructions**: See [`main/README.md`](main/README.md) for detailed setup and usage
3. **Pre-computed Data**: Access our perturbations dataset on [Hugging Face](https://huggingface.co/datasets/abharadwaj123/preference-model-perturbations)

## ğŸ“Š Supported Bias Types

- **Length Bias**: Mitigate preferences for response length
- **Vagueness Bias**: Balance specific vs. general responses
- **Jargon Bias**: Control technical language usage
- **Structure Bias**: Address format preferences
- **Sycophancy Bias**: Reduce excessive agreeableness

## ğŸ“š Additional Resources

- **Paper Artifacts**: `data_utils/`, `human_annotation_data/`, and `llm_evaluation_data/` contain supplementary materials for our research paper
- **Human Annotations**: Curated examples for each bias type in `human_annotation_data/`
- **Evaluation Data**: LLM-based evaluation results in `llm_evaluation_data/`

## ğŸ”— Related Links

- [Detailed Documentation](main/README.md)
- [Pre-computed Perturbations](https://huggingface.co/datasets/abharadwaj123/preference-model-perturbations)

---

**Note**: For installation, configuration, and step-by-step usage instructions, please refer to [`main/README.md`](main/README.md).