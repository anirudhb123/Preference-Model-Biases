/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-05-12 13:51:52 - INFO - __main__ - Loading model: Skywork/Skywork-Reward-Llama-3.1-8B-v0.2
2025-05-12 13:51:52 - INFO - __main__ - Loading PEFT adapter: abharadwaj123/skywork-8b-fine-tuned-structure-750-3
[INFO|configuration_utils.py:699] 2025-05-12 13:51:52,916 >> loading configuration file config.json from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Llama-3.1-8B-v0.2/snapshots/d4117fbfd81b72f41b96341238baa1e3e90a4ce1/config.json
[INFO|configuration_utils.py:771] 2025-05-12 13:51:52,917 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForSequenceClassification"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": [
    128001,
    128008,
    128009
  ],
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "label2id": {
    "LABEL_0": 0
  },
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pad_token_id": 128004,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 8.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.50.3",
  "use_cache": false,
  "vocab_size": 128256
}

[INFO|modeling_utils.py:1154] 2025-05-12 13:51:53,402 >> loading weights file model.safetensors from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Llama-3.1-8B-v0.2/snapshots/d4117fbfd81b72f41b96341238baa1e3e90a4ce1/model.safetensors.index.json
[INFO|modeling_utils.py:2170] 2025-05-12 13:51:53,417 >> Instantiating LlamaForSequenceClassification model under default dtype torch.bfloat16.

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.04s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.28it/s]
[INFO|modeling_utils.py:4987] 2025-05-12 13:51:56,943 >> All model checkpoint weights were used when initializing LlamaForSequenceClassification.

[INFO|modeling_utils.py:4995] 2025-05-12 13:51:56,944 >> All the weights of LlamaForSequenceClassification were initialized from the model checkpoint at Skywork/Skywork-Reward-Llama-3.1-8B-v0.2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForSequenceClassification for predictions without further training.
[INFO|tokenization_utils_base.py:2060] 2025-05-12 13:51:57,494 >> loading file tokenizer.json from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Llama-3.1-8B-v0.2/snapshots/d4117fbfd81b72f41b96341238baa1e3e90a4ce1/tokenizer.json
[INFO|tokenization_utils_base.py:2060] 2025-05-12 13:51:57,494 >> loading file tokenizer.model from cache at None
[INFO|tokenization_utils_base.py:2060] 2025-05-12 13:51:57,494 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2060] 2025-05-12 13:51:57,494 >> loading file special_tokens_map.json from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Llama-3.1-8B-v0.2/snapshots/d4117fbfd81b72f41b96341238baa1e3e90a4ce1/special_tokens_map.json
[INFO|tokenization_utils_base.py:2060] 2025-05-12 13:51:57,494 >> loading file tokenizer_config.json from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Llama-3.1-8B-v0.2/snapshots/d4117fbfd81b72f41b96341238baa1e3e90a4ce1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2060] 2025-05-12 13:51:57,494 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2323] 2025-05-12 13:51:57,865 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2025-05-12 13:51:59 - INFO - __main__ - *** Preparing dataset with HF Transformers ***

Map (num_proc=8):   0%|          | 0/2985 [00:00<?, ? examples/s]
Map (num_proc=8):   0%|          | 1/2985 [00:02<1:56:04,  2.33s/ examples]
Map (num_proc=8):  13%|█▎        | 374/2985 [00:03<00:16, 161.24 examples/s]
Map (num_proc=8):  23%|██▎       | 688/2985 [00:03<00:09, 239.36 examples/s]
Map (num_proc=8):  44%|████▍     | 1308/2985 [00:03<00:02, 571.33 examples/s]
Map (num_proc=8):  53%|█████▎    | 1575/2985 [00:04<00:02, 549.01 examples/s]
Map (num_proc=8):  59%|█████▉    | 1773/2985 [00:04<00:01, 645.22 examples/s]
Map (num_proc=8):  68%|██████▊   | 2023/2985 [00:04<00:01, 665.90 examples/s]
Map (num_proc=8):  74%|███████▍  | 2223/2985 [00:05<00:00, 796.64 examples/s]
Map (num_proc=8):  85%|████████▍ | 2528/2985 [00:05<00:00, 1066.52 examples/s]
Map (num_proc=8):  96%|█████████▋| 2874/2985 [00:05<00:00, 1165.52 examples/s]
Map (num_proc=8): 100%|██████████| 2985/2985 [00:05<00:00, 534.28 examples/s] 
[WARNING|base.py:978] 2025-05-12 13:52:05,293 >> Device set to use cuda:0
[ERROR|base.py:1218] 2025-05-12 13:52:05,294 >> The model 'PeftModelForSequenceClassification' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DiffLlamaForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'Gemma2ForSequenceClassification', 'GlmForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'HeliumForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'JetMoeForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'ModernBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NemotronForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'Phi3ForSequenceClassification', 'PhimoeForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification', 'ZambaForSequenceClassification', 'Zamba2ForSequenceClassification', 'GPTNeoXRewardModel'].
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(

Processing batches:   0%|          | 0/374 [00:00<?, ?it/s]/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[INFO|base.py:1299] 2025-05-12 13:52:21,071 >> Disabling tokenizer parallelism, we're using DataLoader multithreading already

Processing batches:   0%|          | 1/374 [00:17<1:46:54, 17.20s/it]
Processing batches:   1%|          | 2/374 [00:18<47:37,  7.68s/it]  
Processing batches:   1%|          | 3/374 [00:19<29:06,  4.71s/it]
Processing batches:   1%|          | 4/374 [00:20<20:32,  3.33s/it]
Processing batches:   1%|▏         | 5/374 [00:22<16:22,  2.66s/it][WARNING|logging.py:329] 2025-05-12 13:52:27,382 >> You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

Processing batches:   2%|▏         | 6/374 [00:23<13:07,  2.14s/it]
Processing batches:   2%|▏         | 7/374 [00:24<10:56,  1.79s/it]
Processing batches:   2%|▏         | 8/374 [00:25<10:14,  1.68s/it]
Processing batches:   2%|▏         | 9/374 [00:27<09:50,  1.62s/it]
Processing batches:   3%|▎         | 10/374 [00:28<09:21,  1.54s/it]
Processing batches:   3%|▎         | 11/374 [00:29<08:34,  1.42s/it]
Processing batches:   3%|▎         | 12/374 [00:30<07:52,  1.31s/it]
Processing batches:   3%|▎         | 13/374 [00:32<07:57,  1.32s/it]
Processing batches:   4%|▎         | 14/374 [00:33<07:51,  1.31s/it]
Processing batches:   4%|▍         | 15/374 [00:34<07:31,  1.26s/it]
Processing batches:   4%|▍         | 16/374 [00:35<07:06,  1.19s/it]
Processing batches:   5%|▍         | 17/374 [00:37<07:35,  1.28s/it]
Processing batches:   5%|▍         | 18/374 [00:38<07:07,  1.20s/it]
Processing batches:   5%|▌         | 19/374 [00:39<06:54,  1.17s/it]
Processing batches:   5%|▌         | 20/374 [00:40<07:18,  1.24s/it]
Processing batches:   6%|▌         | 21/374 [00:41<07:35,  1.29s/it]
Processing batches:   6%|▌         | 22/374 [00:43<07:31,  1.28s/it]
Processing batches:   6%|▌         | 23/374 [00:44<06:38,  1.13s/it]
Processing batches:   6%|▋         | 24/374 [00:45<06:25,  1.10s/it]
Processing batches:   7%|▋         | 25/374 [00:46<07:04,  1.22s/it]
Processing batches:   7%|▋         | 26/374 [00:48<07:31,  1.30s/it]
Processing batches:   7%|▋         | 27/374 [00:49<07:51,  1.36s/it]
Processing batches:   7%|▋         | 28/374 [00:51<08:03,  1.40s/it]
Processing batches:   8%|▊         | 29/374 [00:52<08:12,  1.43s/it]
Processing batches:   8%|▊         | 30/374 [00:54<08:17,  1.45s/it]
Processing batches:   8%|▊         | 31/374 [00:55<08:18,  1.45s/it]
Processing batches:   9%|▊         | 32/374 [00:56<08:21,  1.47s/it]
Processing batches:   9%|▉         | 33/374 [00:58<08:23,  1.48s/it]
Processing batches:   9%|▉         | 34/374 [00:59<08:15,  1.46s/it]
Processing batches:   9%|▉         | 35/374 [01:01<08:01,  1.42s/it]
Processing batches:  10%|▉         | 36/374 [01:02<08:07,  1.44s/it]
Processing batches:  10%|▉         | 37/374 [01:04<08:11,  1.46s/it]
Processing batches:  10%|█         | 38/374 [01:05<08:06,  1.45s/it]
Processing batches:  10%|█         | 39/374 [01:07<08:10,  1.46s/it]
Processing batches:  11%|█         | 40/374 [01:08<08:12,  1.47s/it]
Processing batches:  11%|█         | 41/374 [01:09<07:56,  1.43s/it]
Processing batches:  11%|█         | 42/374 [01:11<07:53,  1.43s/it]
Processing batches:  11%|█▏        | 43/374 [01:12<07:42,  1.40s/it]
Processing batches:  12%|█▏        | 44/374 [01:14<07:50,  1.43s/it]
Processing batches:  12%|█▏        | 45/374 [01:15<07:55,  1.45s/it]
Processing batches:  12%|█▏        | 46/374 [01:16<07:37,  1.39s/it]
Processing batches:  13%|█▎        | 47/374 [01:18<07:40,  1.41s/it]
Processing batches:  13%|█▎        | 48/374 [01:19<07:01,  1.29s/it]
Processing batches:  13%|█▎        | 49/374 [01:20<07:20,  1.35s/it]
Processing batches:  13%|█▎        | 50/374 [01:21<06:49,  1.26s/it]
Processing batches:  14%|█▎        | 51/374 [01:23<07:10,  1.33s/it]
Processing batches:  14%|█▍        | 52/374 [01:24<06:49,  1.27s/it]
Processing batches:  14%|█▍        | 53/374 [01:25<06:44,  1.26s/it]
Processing batches:  14%|█▍        | 54/374 [01:26<05:17,  1.01it/s]
Processing batches:  15%|█▍        | 55/374 [01:26<04:11,  1.27it/s]
Processing batches:  15%|█▍        | 56/374 [01:27<04:46,  1.11it/s]
Processing batches:  15%|█▌        | 57/374 [01:29<05:42,  1.08s/it]
Processing batches:  16%|█▌        | 58/374 [01:29<05:00,  1.05it/s]
Processing batches:  16%|█▌        | 59/374 [01:30<04:50,  1.08it/s]
Processing batches:  16%|█▌        | 60/374 [01:31<04:02,  1.29it/s]
Processing batches:  16%|█▋        | 61/374 [01:31<03:47,  1.38it/s]
Processing batches:  17%|█▋        | 62/374 [01:32<03:51,  1.35it/s]
Processing batches:  17%|█▋        | 63/374 [01:32<03:25,  1.52it/s]
Processing batches:  17%|█▋        | 64/374 [01:33<03:04,  1.68it/s]
Processing batches:  17%|█▋        | 65/374 [01:34<03:30,  1.47it/s]
Processing batches:  18%|█▊        | 66/374 [01:34<03:11,  1.61it/s]
Processing batches:  18%|█▊        | 67/374 [01:35<03:11,  1.60it/s]
Processing batches:  18%|█▊        | 68/374 [01:35<03:06,  1.64it/s]
Processing batches:  18%|█▊        | 69/374 [01:36<02:44,  1.85it/s]
Processing batches:  19%|█▊        | 70/374 [01:36<02:31,  2.00it/s]
Processing batches:  19%|█▉        | 71/374 [01:37<02:40,  1.89it/s]
Processing batches:  19%|█▉        | 72/374 [01:37<02:38,  1.90it/s]
Processing batches:  20%|█▉        | 73/374 [01:38<03:24,  1.47it/s]
Processing batches:  20%|█▉        | 74/374 [01:39<03:37,  1.38it/s]
Processing batches:  20%|██        | 75/374 [01:40<04:22,  1.14it/s]
Processing batches:  20%|██        | 76/374 [01:41<04:32,  1.09it/s]
Processing batches:  21%|██        | 77/374 [01:43<04:56,  1.00it/s]
Processing batches:  21%|██        | 78/374 [01:44<04:58,  1.01s/it]
Processing batches:  21%|██        | 79/374 [01:45<05:40,  1.16s/it]
Processing batches:  21%|██▏       | 80/374 [01:46<05:44,  1.17s/it]
Processing batches:  22%|██▏       | 81/374 [01:48<05:40,  1.16s/it]
Processing batches:  22%|██▏       | 82/374 [01:49<05:28,  1.12s/it]
Processing batches:  22%|██▏       | 83/374 [01:50<05:19,  1.10s/it]
Processing batches:  22%|██▏       | 84/374 [01:51<05:31,  1.14s/it]
Processing batches:  23%|██▎       | 85/374 [01:52<05:51,  1.22s/it]
Processing batches:  23%|██▎       | 86/374 [01:54<06:05,  1.27s/it]
Processing batches:  23%|██▎       | 87/374 [01:55<06:24,  1.34s/it]
Processing batches:  24%|██▎       | 88/374 [01:57<06:30,  1.36s/it]
Processing batches:  24%|██▍       | 89/374 [01:58<06:28,  1.36s/it]
Processing batches:  24%|██▍       | 90/374 [01:59<06:21,  1.34s/it]
Processing batches:  24%|██▍       | 91/374 [02:00<05:12,  1.11s/it]
Processing batches:  25%|██▍       | 92/374 [02:00<04:21,  1.08it/s]
Processing batches:  25%|██▍       | 93/374 [02:01<03:41,  1.27it/s]
Processing batches:  25%|██▌       | 94/374 [02:02<03:48,  1.22it/s]
Processing batches:  25%|██▌       | 95/374 [02:03<04:17,  1.08it/s]
Processing batches:  26%|██▌       | 96/374 [02:03<03:55,  1.18it/s]
Processing batches:  26%|██▌       | 97/374 [02:05<04:35,  1.01it/s]
Processing batches:  26%|██▌       | 98/374 [02:06<05:16,  1.15s/it]
Processing batches:  26%|██▋       | 99/374 [02:08<05:28,  1.19s/it]
Processing batches:  27%|██▋       | 100/374 [02:09<05:14,  1.15s/it]
Processing batches:  27%|██▋       | 101/374 [02:10<05:32,  1.22s/it]
Processing batches:  27%|██▋       | 102/374 [02:11<05:14,  1.16s/it]
Processing batches:  28%|██▊       | 103/374 [02:12<05:13,  1.16s/it]
Processing batches:  28%|██▊       | 104/374 [02:13<05:12,  1.16s/it]
Processing batches:  28%|██▊       | 105/374 [02:15<05:16,  1.18s/it]
Processing batches:  28%|██▊       | 106/374 [02:16<05:14,  1.17s/it]
Processing batches:  29%|██▊       | 107/374 [02:17<04:59,  1.12s/it]
Processing batches:  29%|██▉       | 108/374 [02:18<05:02,  1.14s/it]
Processing batches:  29%|██▉       | 109/374 [02:19<05:02,  1.14s/it]
Processing batches:  29%|██▉       | 110/374 [02:20<05:01,  1.14s/it]
Processing batches:  30%|██▉       | 111/374 [02:22<05:09,  1.18s/it]
Processing batches:  30%|██▉       | 112/374 [02:23<05:06,  1.17s/it]
Processing batches:  30%|███       | 113/374 [02:24<04:59,  1.15s/it]
Processing batches:  30%|███       | 114/374 [02:25<05:04,  1.17s/it]
Processing batches:  31%|███       | 115/374 [02:26<05:06,  1.18s/it]
Processing batches:  31%|███       | 116/374 [02:27<04:50,  1.13s/it]
Processing batches:  31%|███▏      | 117/374 [02:28<04:42,  1.10s/it]
Processing batches:  32%|███▏      | 118/374 [02:29<04:30,  1.06s/it]
Processing batches:  32%|███▏      | 119/374 [02:30<04:31,  1.06s/it]
Processing batches:  32%|███▏      | 120/374 [02:31<04:25,  1.05s/it]
Processing batches:  32%|███▏      | 121/374 [02:32<04:24,  1.04s/it]
Processing batches:  33%|███▎      | 122/374 [02:33<04:26,  1.06s/it]
Processing batches:  33%|███▎      | 123/374 [02:34<03:56,  1.06it/s]
Processing batches:  33%|███▎      | 124/374 [02:35<04:08,  1.01it/s]
Processing batches:  33%|███▎      | 125/374 [02:36<04:18,  1.04s/it]
Processing batches:  34%|███▎      | 126/374 [02:37<04:23,  1.06s/it]
Processing batches:  34%|███▍      | 127/374 [02:39<04:31,  1.10s/it]
Processing batches:  34%|███▍      | 128/374 [02:39<04:10,  1.02s/it]
Processing batches:  34%|███▍      | 129/374 [02:40<04:03,  1.00it/s]
Processing batches:  35%|███▍      | 130/374 [02:41<04:00,  1.02it/s]
Processing batches:  35%|███▌      | 131/374 [02:42<03:54,  1.04it/s]
Processing batches:  35%|███▌      | 132/374 [02:43<03:58,  1.01it/s]
Processing batches:  36%|███▌      | 133/374 [02:44<03:46,  1.06it/s]
Processing batches:  36%|███▌      | 134/374 [02:45<03:39,  1.09it/s]
Processing batches:  36%|███▌      | 135/374 [02:46<03:31,  1.13it/s]
Processing batches:  36%|███▋      | 136/374 [02:47<03:28,  1.14it/s]
Processing batches:  37%|███▋      | 137/374 [02:47<03:21,  1.17it/s]
Processing batches:  37%|███▋      | 138/374 [02:48<03:24,  1.16it/s]
Processing batches:  37%|███▋      | 139/374 [02:49<03:20,  1.17it/s]
Processing batches:  37%|███▋      | 140/374 [02:50<03:14,  1.20it/s]
Processing batches:  38%|███▊      | 141/374 [02:51<03:14,  1.20it/s]
Processing batches:  38%|███▊      | 142/374 [02:52<03:12,  1.20it/s]
Processing batches:  38%|███▊      | 143/374 [02:53<03:15,  1.18it/s]
Processing batches:  39%|███▊      | 144/374 [02:54<03:35,  1.07it/s]
Processing batches:  39%|███▉      | 145/374 [02:55<03:39,  1.05it/s]
Processing batches:  39%|███▉      | 146/374 [02:56<03:33,  1.07it/s]
Processing batches:  39%|███▉      | 147/374 [02:57<04:02,  1.07s/it]
Processing batches:  40%|███▉      | 148/374 [02:58<03:55,  1.04s/it]
Processing batches:  40%|███▉      | 149/374 [02:59<03:57,  1.06s/it]
Processing batches:  40%|████      | 150/374 [03:00<03:46,  1.01s/it]
Processing batches:  40%|████      | 151/374 [03:01<03:26,  1.08it/s]
Processing batches:  41%|████      | 152/374 [03:01<03:14,  1.14it/s]
Processing batches:  41%|████      | 153/374 [03:02<02:57,  1.24it/s]
Processing batches:  41%|████      | 154/374 [03:03<02:57,  1.24it/s]
Processing batches:  41%|████▏     | 155/374 [03:04<02:55,  1.25it/s]
Processing batches:  42%|████▏     | 156/374 [03:05<03:13,  1.13it/s]
Processing batches:  42%|████▏     | 157/374 [03:05<03:05,  1.17it/s]
Processing batches:  42%|████▏     | 158/374 [03:06<02:56,  1.22it/s]
Processing batches:  43%|████▎     | 159/374 [03:07<02:42,  1.33it/s]
Processing batches:  43%|████▎     | 160/374 [03:07<02:31,  1.41it/s]
Processing batches:  43%|████▎     | 161/374 [03:08<02:27,  1.44it/s]
Processing batches:  43%|████▎     | 162/374 [03:09<02:22,  1.49it/s]
Processing batches:  44%|████▎     | 163/374 [03:10<02:33,  1.38it/s]
Processing batches:  44%|████▍     | 164/374 [03:10<02:41,  1.30it/s]
Processing batches:  44%|████▍     | 165/374 [03:11<02:41,  1.29it/s]
Processing batches:  44%|████▍     | 166/374 [03:12<02:47,  1.24it/s]
Processing batches:  45%|████▍     | 167/374 [03:13<02:49,  1.22it/s]
Processing batches:  45%|████▍     | 168/374 [03:14<02:43,  1.26it/s]
Processing batches:  45%|████▌     | 169/374 [03:14<02:33,  1.34it/s]
Processing batches:  45%|████▌     | 170/374 [03:15<02:26,  1.39it/s]
Processing batches:  46%|████▌     | 171/374 [03:16<02:23,  1.41it/s]
Processing batches:  46%|████▌     | 172/374 [03:16<02:02,  1.65it/s]
Processing batches:  46%|████▋     | 173/374 [03:16<01:46,  1.89it/s]
Processing batches:  47%|████▋     | 174/374 [03:17<01:34,  2.11it/s]
Processing batches:  47%|████▋     | 175/374 [03:17<01:50,  1.79it/s]
Processing batches:  47%|████▋     | 176/374 [03:18<01:43,  1.92it/s]
Processing batches:  47%|████▋     | 177/374 [03:19<01:54,  1.72it/s]
Processing batches:  48%|████▊     | 178/374 [03:20<02:21,  1.39it/s]
Processing batches:  48%|████▊     | 179/374 [03:21<02:41,  1.21it/s]
Processing batches:  48%|████▊     | 180/374 [03:22<02:58,  1.08it/s]
Processing batches:  48%|████▊     | 181/374 [03:23<03:23,  1.05s/it]
Processing batches:  49%|████▊     | 182/374 [03:24<02:59,  1.07it/s]
Processing batches:  49%|████▉     | 183/374 [03:25<02:53,  1.10it/s]
Processing batches:  49%|████▉     | 184/374 [03:26<03:08,  1.01it/s]
Processing batches:  49%|████▉     | 185/374 [03:27<03:13,  1.03s/it]
Processing batches:  50%|████▉     | 186/374 [03:28<03:36,  1.15s/it]
Processing batches:  50%|█████     | 187/374 [03:30<03:34,  1.15s/it]
Processing batches:  50%|█████     | 188/374 [03:30<03:12,  1.04s/it]
Processing batches:  51%|█████     | 189/374 [03:32<03:18,  1.07s/it]
Processing batches:  51%|█████     | 190/374 [03:33<03:39,  1.19s/it]
Processing batches:  51%|█████     | 191/374 [03:34<03:49,  1.26s/it]
Processing batches:  51%|█████▏    | 192/374 [03:36<03:55,  1.30s/it]
Processing batches:  52%|█████▏    | 193/374 [03:37<04:04,  1.35s/it]
Processing batches:  52%|█████▏    | 194/374 [03:38<03:45,  1.26s/it]
Processing batches:  52%|█████▏    | 195/374 [03:39<03:21,  1.13s/it]
Processing batches:  52%|█████▏    | 196/374 [03:40<02:55,  1.02it/s]
Processing batches:  53%|█████▎    | 197/374 [03:41<02:46,  1.06it/s]
Processing batches:  53%|█████▎    | 198/374 [03:41<02:29,  1.18it/s]
Processing batches:  53%|█████▎    | 199/374 [03:42<02:31,  1.16it/s]
Processing batches:  53%|█████▎    | 200/374 [03:43<02:22,  1.22it/s]
Processing batches:  54%|█████▎    | 201/374 [03:44<02:19,  1.24it/s]
Processing batches:  54%|█████▍    | 202/374 [03:44<02:04,  1.38it/s]
Processing batches:  54%|█████▍    | 203/374 [03:45<02:22,  1.20it/s]
Processing batches:  55%|█████▍    | 204/374 [03:46<02:24,  1.17it/s]
Processing batches:  55%|█████▍    | 205/374 [03:48<02:57,  1.05s/it]
Processing batches:  55%|█████▌    | 206/374 [03:49<02:50,  1.02s/it]
Processing batches:  55%|█████▌    | 207/374 [03:50<02:58,  1.07s/it]
Processing batches:  56%|█████▌    | 208/374 [03:51<03:02,  1.10s/it]
Processing batches:  56%|█████▌    | 209/374 [03:52<02:56,  1.07s/it]
Processing batches:  56%|█████▌    | 210/374 [03:53<03:03,  1.12s/it]
Processing batches:  56%|█████▋    | 211/374 [03:55<03:21,  1.24s/it]
Processing batches:  57%|█████▋    | 212/374 [03:56<03:09,  1.17s/it]
Processing batches:  57%|█████▋    | 213/374 [03:57<03:03,  1.14s/it]
Processing batches:  57%|█████▋    | 214/374 [03:58<03:07,  1.17s/it]
Processing batches:  57%|█████▋    | 215/374 [03:59<02:53,  1.09s/it]
Processing batches:  58%|█████▊    | 216/374 [04:00<02:37,  1.00it/s]
Processing batches:  58%|█████▊    | 217/374 [04:01<02:26,  1.07it/s]
Processing batches:  58%|█████▊    | 218/374 [04:02<02:36,  1.00s/it]
Processing batches:  59%|█████▊    | 219/374 [04:03<02:30,  1.03it/s]
Processing batches:  59%|█████▉    | 220/374 [04:03<02:21,  1.09it/s]
Processing batches:  59%|█████▉    | 221/374 [04:04<02:19,  1.10it/s]
Processing batches:  59%|█████▉    | 222/374 [04:05<02:11,  1.15it/s]
Processing batches:  60%|█████▉    | 223/374 [04:06<02:04,  1.21it/s]
Processing batches:  60%|█████▉    | 224/374 [04:07<02:27,  1.02it/s]
Processing batches:  60%|██████    | 225/374 [04:09<02:50,  1.14s/it]
Processing batches:  60%|██████    | 226/374 [04:10<02:50,  1.15s/it]
Processing batches:  61%|██████    | 227/374 [04:11<02:58,  1.21s/it]
Processing batches:  61%|██████    | 228/374 [04:12<02:58,  1.22s/it]
Processing batches:  61%|██████    | 229/374 [04:14<03:09,  1.31s/it]
Processing batches:  61%|██████▏   | 230/374 [04:15<03:01,  1.26s/it]
Processing batches:  62%|██████▏   | 231/374 [04:17<03:10,  1.33s/it]
Processing batches:  62%|██████▏   | 232/374 [04:18<03:04,  1.30s/it]
Processing batches:  62%|██████▏   | 233/374 [04:19<03:03,  1.30s/it]
Processing batches:  63%|██████▎   | 234/374 [04:20<03:00,  1.29s/it]
Processing batches:  63%|██████▎   | 235/374 [04:22<03:04,  1.32s/it]
Processing batches:  63%|██████▎   | 236/374 [04:23<02:41,  1.17s/it]
Processing batches:  63%|██████▎   | 237/374 [04:23<02:25,  1.06s/it]
Processing batches:  64%|██████▎   | 238/374 [04:24<02:24,  1.06s/it]
Processing batches:  64%|██████▍   | 239/374 [04:25<02:11,  1.02it/s]
Processing batches:  64%|██████▍   | 240/374 [04:26<02:05,  1.07it/s]
Processing batches:  64%|██████▍   | 241/374 [04:27<01:55,  1.15it/s]
Processing batches:  65%|██████▍   | 242/374 [04:28<01:51,  1.19it/s]
Processing batches:  65%|██████▍   | 243/374 [04:28<01:43,  1.27it/s]
Processing batches:  65%|██████▌   | 244/374 [04:29<01:54,  1.13it/s]
Processing batches:  66%|██████▌   | 245/374 [04:30<01:55,  1.12it/s]
Processing batches:  66%|██████▌   | 246/374 [04:32<02:18,  1.08s/it]
Processing batches:  66%|██████▌   | 247/374 [04:33<02:14,  1.06s/it]
Processing batches:  66%|██████▋   | 248/374 [04:34<02:22,  1.13s/it]
Processing batches:  67%|██████▋   | 249/374 [04:35<02:23,  1.14s/it]
Processing batches:  67%|██████▋   | 250/374 [04:36<02:23,  1.16s/it]
Processing batches:  67%|██████▋   | 251/374 [04:38<02:33,  1.25s/it]
Processing batches:  67%|██████▋   | 252/374 [04:39<02:41,  1.33s/it]
Processing batches:  68%|██████▊   | 253/374 [04:41<02:47,  1.38s/it]
Processing batches:  68%|██████▊   | 254/374 [04:42<02:37,  1.32s/it]
Processing batches:  68%|██████▊   | 255/374 [04:43<02:34,  1.30s/it]
Processing batches:  68%|██████▊   | 256/374 [04:45<02:40,  1.36s/it]
Processing batches:  69%|██████▊   | 257/374 [04:46<02:16,  1.17s/it]
Processing batches:  69%|██████▉   | 258/374 [04:46<01:58,  1.02s/it]
Processing batches:  69%|██████▉   | 259/374 [04:47<01:54,  1.01it/s]
Processing batches:  70%|██████▉   | 260/374 [04:48<01:50,  1.03it/s]
Processing batches:  70%|██████▉   | 261/374 [04:49<01:43,  1.09it/s]
Processing batches:  70%|███████   | 262/374 [04:50<01:38,  1.13it/s]
Processing batches:  70%|███████   | 263/374 [04:50<01:26,  1.28it/s]
Processing batches:  71%|███████   | 264/374 [04:51<01:22,  1.34it/s]
Processing batches:  71%|███████   | 265/374 [04:52<01:33,  1.17it/s]
Processing batches:  71%|███████   | 266/374 [04:54<01:53,  1.05s/it]
Processing batches:  71%|███████▏  | 267/374 [04:55<01:54,  1.07s/it]
Processing batches:  72%|███████▏  | 268/374 [04:56<02:02,  1.16s/it]
Processing batches:  72%|███████▏  | 269/374 [04:58<02:13,  1.27s/it]
Processing batches:  72%|███████▏  | 270/374 [04:59<02:14,  1.29s/it]
Processing batches:  72%|███████▏  | 271/374 [05:00<02:20,  1.36s/it]
Processing batches:  73%|███████▎  | 272/374 [05:02<02:23,  1.41s/it]
Processing batches:  73%|███████▎  | 273/374 [05:03<02:14,  1.33s/it]
Processing batches:  73%|███████▎  | 274/374 [05:04<02:09,  1.30s/it]
Processing batches:  74%|███████▎  | 275/374 [05:06<02:12,  1.34s/it]
Processing batches:  74%|███████▍  | 276/374 [05:07<02:16,  1.39s/it]
Processing batches:  74%|███████▍  | 277/374 [05:08<01:54,  1.18s/it]
Processing batches:  74%|███████▍  | 278/374 [05:09<01:38,  1.03s/it]
Processing batches:  75%|███████▍  | 279/374 [05:10<01:43,  1.09s/it]
Processing batches:  75%|███████▍  | 280/374 [05:10<01:26,  1.08it/s]
Processing batches:  75%|███████▌  | 281/374 [05:11<01:21,  1.14it/s]
Processing batches:  75%|███████▌  | 282/374 [05:12<01:14,  1.23it/s]
Processing batches:  76%|███████▌  | 283/374 [05:13<01:20,  1.13it/s]
Processing batches:  76%|███████▌  | 284/374 [05:13<01:09,  1.30it/s]
Processing batches:  76%|███████▌  | 285/374 [05:14<01:09,  1.28it/s]
Processing batches:  76%|███████▋  | 286/374 [05:15<01:07,  1.31it/s]
Processing batches:  77%|███████▋  | 287/374 [05:16<01:25,  1.01it/s]
Processing batches:  77%|███████▋  | 288/374 [05:17<01:20,  1.06it/s]
Processing batches:  77%|███████▋  | 289/374 [05:18<01:14,  1.14it/s]
Processing batches:  78%|███████▊  | 290/374 [05:19<01:14,  1.13it/s]
Processing batches:  78%|███████▊  | 291/374 [05:20<01:16,  1.08it/s]
Processing batches:  78%|███████▊  | 292/374 [05:21<01:29,  1.09s/it]
Processing batches:  78%|███████▊  | 293/374 [05:23<01:38,  1.21s/it]
Processing batches:  79%|███████▊  | 294/374 [05:24<01:44,  1.30s/it]
Processing batches:  79%|███████▉  | 295/374 [05:26<01:40,  1.27s/it]
Processing batches:  79%|███████▉  | 296/374 [05:27<01:38,  1.26s/it]
Processing batches:  79%|███████▉  | 297/374 [05:28<01:42,  1.33s/it]
Processing batches:  80%|███████▉  | 298/374 [05:29<01:28,  1.17s/it]
Processing batches:  80%|███████▉  | 299/374 [05:30<01:18,  1.05s/it]
Processing batches:  80%|████████  | 300/374 [05:31<01:21,  1.10s/it]
Processing batches:  80%|████████  | 301/374 [05:32<01:16,  1.04s/it]
Processing batches:  81%|████████  | 302/374 [05:33<01:10,  1.02it/s]
Processing batches:  81%|████████  | 303/374 [05:34<01:07,  1.06it/s]
Processing batches:  81%|████████▏ | 304/374 [05:34<01:00,  1.16it/s]
Processing batches:  82%|████████▏ | 305/374 [05:35<00:56,  1.22it/s]
Processing batches:  82%|████████▏ | 306/374 [05:36<01:07,  1.01it/s]
Processing batches:  82%|████████▏ | 307/374 [05:38<01:16,  1.14s/it]
Processing batches:  82%|████████▏ | 308/374 [05:39<01:15,  1.14s/it]
Processing batches:  83%|████████▎ | 309/374 [05:40<01:18,  1.21s/it]
Processing batches:  83%|████████▎ | 310/374 [05:42<01:20,  1.26s/it]
Processing batches:  83%|████████▎ | 311/374 [05:43<01:21,  1.29s/it]
Processing batches:  83%|████████▎ | 312/374 [05:44<01:16,  1.23s/it]
Processing batches:  84%|████████▎ | 313/374 [05:46<01:20,  1.31s/it]
Processing batches:  84%|████████▍ | 314/374 [05:47<01:16,  1.27s/it]
Processing batches:  84%|████████▍ | 315/374 [05:48<01:11,  1.22s/it]
Processing batches:  84%|████████▍ | 316/374 [05:49<01:10,  1.22s/it]
Processing batches:  85%|████████▍ | 317/374 [05:51<01:14,  1.31s/it]
Processing batches:  85%|████████▌ | 318/374 [05:52<01:16,  1.37s/it]
Processing batches:  85%|████████▌ | 319/374 [05:54<01:17,  1.41s/it]
Processing batches:  86%|████████▌ | 320/374 [05:55<01:18,  1.45s/it]
Processing batches:  86%|████████▌ | 321/374 [05:57<01:17,  1.47s/it]
Processing batches:  86%|████████▌ | 322/374 [05:58<01:17,  1.48s/it]
Processing batches:  86%|████████▋ | 323/374 [06:00<01:16,  1.49s/it]
Processing batches:  87%|████████▋ | 324/374 [06:01<01:15,  1.50s/it]
Processing batches:  87%|████████▋ | 325/374 [06:03<01:11,  1.46s/it]
Processing batches:  87%|████████▋ | 326/374 [06:04<01:10,  1.48s/it]
Processing batches:  87%|████████▋ | 327/374 [06:06<01:09,  1.49s/it]
Processing batches:  88%|████████▊ | 328/374 [06:07<01:08,  1.50s/it]
Processing batches:  88%|████████▊ | 329/374 [06:09<01:07,  1.50s/it]
Processing batches:  88%|████████▊ | 330/374 [06:10<01:06,  1.51s/it]
Processing batches:  89%|████████▊ | 331/374 [06:12<01:04,  1.51s/it]
Processing batches:  89%|████████▉ | 332/374 [06:13<01:02,  1.50s/it]
Processing batches:  89%|████████▉ | 333/374 [06:15<01:01,  1.49s/it]
Processing batches:  89%|████████▉ | 334/374 [06:16<00:57,  1.45s/it]
Processing batches:  90%|████████▉ | 335/374 [06:18<00:57,  1.47s/it]
Processing batches:  90%|████████▉ | 336/374 [06:19<00:56,  1.48s/it]
Processing batches:  90%|█████████ | 337/374 [06:21<00:55,  1.49s/it]
Processing batches:  90%|█████████ | 338/374 [06:22<00:53,  1.48s/it]
Processing batches:  91%|█████████ | 339/374 [06:24<00:51,  1.48s/it]
Processing batches:  91%|█████████ | 340/374 [06:25<00:50,  1.49s/it]
Processing batches:  91%|█████████ | 341/374 [06:27<00:49,  1.50s/it]
Processing batches:  91%|█████████▏| 342/374 [06:28<00:48,  1.50s/it]
Processing batches:  92%|█████████▏| 343/374 [06:29<00:44,  1.44s/it]
Processing batches:  92%|█████████▏| 344/374 [06:31<00:41,  1.40s/it]
Processing batches:  92%|█████████▏| 345/374 [06:32<00:41,  1.43s/it]
Processing batches:  93%|█████████▎| 346/374 [06:34<00:39,  1.42s/it]
Processing batches:  93%|█████████▎| 347/374 [06:35<00:39,  1.45s/it]
Processing batches:  93%|█████████▎| 348/374 [06:37<00:38,  1.47s/it]
Processing batches:  93%|█████████▎| 349/374 [06:38<00:35,  1.41s/it]
Processing batches:  94%|█████████▎| 350/374 [06:39<00:32,  1.37s/it]
Processing batches:  94%|█████████▍| 351/374 [06:41<00:32,  1.41s/it]
Processing batches:  94%|█████████▍| 352/374 [06:42<00:29,  1.36s/it]
Processing batches:  94%|█████████▍| 353/374 [06:43<00:28,  1.34s/it]
Processing batches:  95%|█████████▍| 354/374 [06:45<00:27,  1.38s/it]
Processing batches:  95%|█████████▍| 355/374 [06:46<00:25,  1.32s/it]
Processing batches:  95%|█████████▌| 356/374 [06:47<00:24,  1.38s/it]
Processing batches:  95%|█████████▌| 357/374 [06:49<00:23,  1.38s/it]
Processing batches:  96%|█████████▌| 358/374 [06:50<00:22,  1.42s/it]
Processing batches:  96%|█████████▌| 359/374 [06:52<00:21,  1.44s/it]
Processing batches:  96%|█████████▋| 360/374 [06:53<00:19,  1.39s/it]
Processing batches:  97%|█████████▋| 361/374 [06:54<00:16,  1.29s/it]
Processing batches:  97%|█████████▋| 362/374 [06:56<00:15,  1.32s/it]
Processing batches:  97%|█████████▋| 363/374 [06:57<00:14,  1.31s/it]
Processing batches:  97%|█████████▋| 364/374 [06:58<00:13,  1.32s/it]
Processing batches:  98%|█████████▊| 365/374 [06:59<00:11,  1.27s/it]
Processing batches:  98%|█████████▊| 366/374 [07:01<00:10,  1.33s/it]
Processing batches:  98%|█████████▊| 367/374 [07:02<00:08,  1.26s/it]
Processing batches:  98%|█████████▊| 368/374 [07:03<00:07,  1.33s/it]
Processing batches:  99%|█████████▊| 369/374 [07:05<00:06,  1.38s/it]
Processing batches:  99%|█████████▉| 370/374 [07:06<00:04,  1.24s/it]
Processing batches:  99%|█████████▉| 371/374 [07:07<00:03,  1.15s/it]
Processing batches:  99%|█████████▉| 372/374 [07:08<00:02,  1.17s/it]
Processing batches: 100%|█████████▉| 373/374 [07:09<00:01,  1.16s/it]
Processing batches: 100%|██████████| 374/374 [07:11<00:00,  1.52s/it]
Processing batches: 100%|██████████| 374/374 [07:11<00:00,  1.15s/it]

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 35256.28 examples/s]
alpacaeval-easy: 0.6200

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 74962.86 examples/s]
alpacaeval-hard: 0.8737

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 71353.65 examples/s]
alpacaeval-length: 0.7684

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 70673.36 examples/s]
donotanswer: 0.7353

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 55267.87 examples/s]
hep-cpp: 0.9268

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 68205.45 examples/s]
hep-go: 0.9329

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 65207.64 examples/s]
hep-java: 0.9390

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 70634.28 examples/s]
hep-js: 0.9573

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 79683.29 examples/s]
hep-python: 0.9634

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 65253.52 examples/s]
hep-rust: 0.9207

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 73895.68 examples/s]
llmbar-adver-GPTInst: 0.8804

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 51750.92 examples/s]
llmbar-adver-GPTOut: 0.8085

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 55013.61 examples/s]
llmbar-adver-manual: 0.8043

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 76130.70 examples/s]
llmbar-adver-neighbor: 0.8881

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 72618.43 examples/s]
llmbar-natural: 0.9100

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 10927.60 examples/s]
math-prm: 0.9441

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 79039.89 examples/s]
mt-bench-easy: 1.0000

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 62387.56 examples/s]
mt-bench-hard: 0.8649

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 68931.33 examples/s]
mt-bench-med: 0.9750

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 68277.61 examples/s]
refusals-dangerous: 0.9400

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 81302.38 examples/s]
refusals-offensive: 0.9900

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 55094.23 examples/s]
xstest-should-refuse: 0.9675

Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]
Filter: 100%|██████████| 2985/2985 [00:00<00:00, 71229.84 examples/s]
xstest-should-respond: 0.9600

Section Scores: {'Chat': 0.7960893854748603, 'Chat Hard': 0.8728070175438597, 'Safety': 0.9216216216216216, 'Reasoning': 0.9420561193866973}
Traceback (most recent call last):
  File "/mnt/nlpgridio3/data/anirudh2/main/rewardbench_eval.py", line 258, in <module>
    main()
  File "/mnt/nlpgridio3/data/anirudh2/main/rewardbench_eval.py", line 247, in main
    save_to_hub(
  File "/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/rewardbench/utils.py", line 112, in save_to_hub
    os.makedirs(dirname, exist_ok=True)  # redundant in Beaker code
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen os>", line 225, in makedirs
PermissionError: [Errno 13] Permission denied: '/output'
