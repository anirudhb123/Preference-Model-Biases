cpu-bind=MASK - nlpgpu06, task  0  0 [14607]: mask 0x100000001 set
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-04-08 23:58:22 - INFO - __main__ - Loading model: Skywork/Skywork-Reward-Gemma-2-27B-v0.2
[INFO|configuration_utils.py:699] 2025-04-08 23:58:22,270 >> loading configuration file config.json from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Gemma-2-27B-v0.2/snapshots/a92f2ec997c806de469ff287ef3b71982e886fc2/config.json
[INFO|configuration_utils.py:771] 2025-04-08 23:58:22,300 >> Model config Gemma2Config {
  "architectures": [
    "Gemma2ForSequenceClassification"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "attn_logit_softcapping": 50.0,
  "bos_token_id": 2,
  "cache_implementation": "hybrid",
  "eos_token_id": 1,
  "final_logit_softcapping": 30.0,
  "head_dim": 128,
  "hidden_act": "gelu_pytorch_tanh",
  "hidden_activation": "gelu_pytorch_tanh",
  "hidden_size": 4608,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 36864,
  "label2id": {
    "LABEL_0": 0
  },
  "max_position_embeddings": 8192,
  "model_type": "gemma2",
  "num_attention_heads": 32,
  "num_hidden_layers": 46,
  "num_key_value_heads": 16,
  "pad_token_id": 0,
  "query_pre_attn_scalar": 144,
  "rms_norm_eps": 1e-06,
  "rope_theta": 10000.0,
  "sliding_window": 4096,
  "sliding_window_size": 4096,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.50.3",
  "use_cache": false,
  "vocab_size": 256000
}

[WARNING|modeling_utils.py:4221] 2025-04-08 23:58:24,963 >> The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
[INFO|modeling_utils.py:1154] 2025-04-08 23:58:25,974 >> loading weights file model.safetensors from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Gemma-2-27B-v0.2/snapshots/a92f2ec997c806de469ff287ef3b71982e886fc2/model.safetensors.index.json
[INFO|modeling_utils.py:2170] 2025-04-08 23:58:26,096 >> Instantiating Gemma2ForSequenceClassification model under default dtype torch.bfloat16.
[INFO|quantizer_bnb_8bit.py:151] 2025-04-08 23:58:26,259 >> target_dtype {target_dtype} is replaced by `torch.int8` for 8-bit BnB quantization
Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:43<07:59, 43.55s/it]Loading checkpoint shards:  17%|█▋        | 2/12 [01:28<07:21, 44.14s/it]Loading checkpoint shards:  25%|██▌       | 3/12 [02:11<06:36, 44.02s/it]Loading checkpoint shards:  33%|███▎      | 4/12 [02:59<06:02, 45.30s/it]Loading checkpoint shards:  42%|████▏     | 5/12 [03:43<05:13, 44.83s/it]Loading checkpoint shards:  50%|█████     | 6/12 [04:27<04:27, 44.52s/it]Loading checkpoint shards:  58%|█████▊    | 7/12 [05:12<03:43, 44.78s/it]Loading checkpoint shards:  67%|██████▋   | 8/12 [05:56<02:58, 44.65s/it]Loading checkpoint shards:  75%|███████▌  | 9/12 [06:40<02:13, 44.48s/it]Loading checkpoint shards:  83%|████████▎ | 10/12 [07:26<01:29, 44.71s/it]Loading checkpoint shards:  92%|█████████▏| 11/12 [08:10<00:44, 44.64s/it]Loading checkpoint shards: 100%|██████████| 12/12 [08:16<00:00, 32.93s/it]Loading checkpoint shards: 100%|██████████| 12/12 [08:16<00:00, 41.40s/it]
[INFO|modeling_utils.py:4987] 2025-04-09 00:06:43,447 >> All model checkpoint weights were used when initializing Gemma2ForSequenceClassification.

[INFO|modeling_utils.py:4995] 2025-04-09 00:06:43,447 >> All the weights of Gemma2ForSequenceClassification were initialized from the model checkpoint at Skywork/Skywork-Reward-Gemma-2-27B-v0.2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Gemma2ForSequenceClassification for predictions without further training.
[INFO|tokenization_utils_base.py:2060] 2025-04-09 00:06:43,822 >> loading file tokenizer.model from cache at None
[INFO|tokenization_utils_base.py:2060] 2025-04-09 00:06:43,822 >> loading file tokenizer.json from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Gemma-2-27B-v0.2/snapshots/a92f2ec997c806de469ff287ef3b71982e886fc2/tokenizer.json
[INFO|tokenization_utils_base.py:2060] 2025-04-09 00:06:43,822 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2060] 2025-04-09 00:06:43,822 >> loading file special_tokens_map.json from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Gemma-2-27B-v0.2/snapshots/a92f2ec997c806de469ff287ef3b71982e886fc2/special_tokens_map.json
[INFO|tokenization_utils_base.py:2060] 2025-04-09 00:06:43,822 >> loading file tokenizer_config.json from cache at /nlp/data/huggingface_cache/models--Skywork--Skywork-Reward-Gemma-2-27B-v0.2/snapshots/a92f2ec997c806de469ff287ef3b71982e886fc2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2060] 2025-04-09 00:06:43,822 >> loading file chat_template.jinja from cache at None
2025-04-09 00:06:47 - INFO - __main__ - *** Preparing dataset with HF Transformers ***
Map (num_proc=8):   0%|          | 0/2985 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 1/2985 [00:04<3:21:19,  4.05s/ examples]Map (num_proc=8):  13%|█▎        | 381/2985 [00:05<00:29, 88.26 examples/s]Map (num_proc=8):  26%|██▌       | 780/2985 [00:07<00:15, 145.07 examples/s]Map (num_proc=8):  38%|███▊      | 1121/2985 [00:08<00:10, 175.13 examples/s]Map (num_proc=8):  51%|█████     | 1529/2985 [00:08<00:05, 265.69 examples/s]Map (num_proc=8):  60%|█████▉    | 1785/2985 [00:09<00:03, 346.12 examples/s]Map (num_proc=8):  64%|██████▍   | 1917/2985 [00:10<00:03, 277.13 examples/s]Map (num_proc=8):  73%|███████▎  | 2172/2985 [00:10<00:02, 377.62 examples/s]Map (num_proc=8):  78%|███████▊  | 2323/2985 [00:10<00:01, 361.91 examples/s]Map (num_proc=8):  88%|████████▊ | 2612/2985 [00:10<00:00, 526.14 examples/s]Map (num_proc=8):  99%|█████████▉| 2957/2985 [00:11<00:00, 634.65 examples/s]Map (num_proc=8): 100%|██████████| 2985/2985 [00:11<00:00, 263.83 examples/s]
[WARNING|base.py:978] 2025-04-09 00:06:59,434 >> Device set to use cuda:0
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Processing batches:   0%|          | 0/374 [00:00<?, ?it/s]/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[INFO|base.py:1299] 2025-04-09 00:07:22,220 >> Disabling tokenizer parallelism, we're using DataLoader multithreading already
/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
Processing batches:   0%|          | 1/374 [00:28<2:58:11, 28.66s/it]Processing batches:   1%|          | 2/374 [00:32<1:26:30, 13.95s/it]Processing batches:   1%|          | 3/374 [00:36<57:54,  9.37s/it]  Processing batches:   1%|          | 4/374 [00:40<45:25,  7.37s/it]Processing batches:   1%|▏         | 5/374 [00:45<39:59,  6.50s/it][WARNING|logging.py:329] 2025-04-09 00:07:44,952 >> You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Processing batches:   2%|▏         | 6/374 [00:49<34:15,  5.58s/it]Processing batches:   2%|▏         | 7/374 [00:53<30:24,  4.97s/it]Processing batches:   2%|▏         | 8/374 [00:57<30:04,  4.93s/it]Processing batches:   2%|▏         | 9/374 [01:02<30:04,  4.94s/it]Processing batches:   3%|▎         | 10/374 [01:07<29:27,  4.86s/it]Processing batches:   3%|▎         | 11/374 [01:11<27:32,  4.55s/it]Processing batches:   3%|▎         | 12/374 [01:14<25:46,  4.27s/it]Processing batches:   3%|▎         | 13/374 [01:19<26:42,  4.44s/it]Processing batches:   4%|▎         | 14/374 [01:24<26:20,  4.39s/it]Processing batches:   4%|▍         | 15/374 [01:27<25:13,  4.22s/it]Processing batches:   4%|▍         | 16/374 [01:31<24:02,  4.03s/it]Processing batches:   5%|▍         | 17/374 [01:36<25:44,  4.33s/it]Processing batches:   5%|▍         | 18/374 [01:40<24:21,  4.10s/it]Processing batches:   5%|▌         | 19/374 [01:43<23:51,  4.03s/it]Processing batches:   5%|▌         | 20/374 [01:48<25:06,  4.26s/it]Processing batches:   6%|▌         | 21/374 [01:53<25:36,  4.35s/it]Processing batches:   6%|▌         | 22/374 [01:57<25:24,  4.33s/it]Processing batches:   6%|▌         | 23/374 [02:00<22:43,  3.89s/it]Processing batches:   6%|▋         | 24/374 [02:04<22:07,  3.79s/it]Processing batches:   7%|▋         | 25/374 [02:09<24:19,  4.18s/it]Processing batches:   7%|▋         | 26/374 [02:14<25:53,  4.46s/it]Processing batches:   7%|▋         | 27/374 [02:19<27:00,  4.67s/it]Processing batches:   7%|▋         | 28/374 [02:24<27:37,  4.79s/it]Processing batches:   8%|▊         | 29/374 [02:29<28:07,  4.89s/it]Processing batches:   8%|▊         | 30/374 [02:34<28:26,  4.96s/it]Processing batches:   8%|▊         | 31/374 [02:39<28:24,  4.97s/it]Processing batches:   9%|▊         | 32/374 [02:44<28:31,  5.01s/it]Processing batches:   9%|▉         | 33/374 [02:49<28:39,  5.04s/it]Processing batches:   9%|▉         | 34/374 [02:54<28:10,  4.97s/it]Processing batches:   9%|▉         | 35/374 [02:59<27:21,  4.84s/it]Processing batches:  10%|▉         | 36/374 [03:04<27:44,  4.92s/it]Processing batches:  10%|▉         | 37/374 [03:09<27:53,  4.97s/it]Processing batches:  10%|█         | 38/374 [03:14<27:34,  4.92s/it]Processing batches:  10%|█         | 39/374 [03:19<27:43,  4.97s/it]Processing batches:  11%|█         | 40/374 [03:24<27:47,  4.99s/it]Processing batches:  11%|█         | 41/374 [03:28<26:47,  4.83s/it]Processing batches:  11%|█         | 42/374 [03:33<26:46,  4.84s/it]Processing batches:  11%|█▏        | 43/374 [03:38<26:03,  4.72s/it]Processing batches:  12%|█▏        | 44/374 [03:43<26:29,  4.82s/it]Processing batches:  12%|█▏        | 45/374 [03:48<26:37,  4.86s/it]Processing batches:  12%|█▏        | 46/374 [03:52<25:10,  4.60s/it]Processing batches:  13%|█▎        | 47/374 [03:56<25:27,  4.67s/it]Processing batches:  13%|█▎        | 48/374 [04:00<23:06,  4.25s/it]Processing batches:  13%|█▎        | 49/374 [04:05<24:07,  4.45s/it]Processing batches:  13%|█▎        | 50/374 [04:08<22:20,  4.14s/it]Processing batches:  14%|█▎        | 51/374 [04:13<23:43,  4.41s/it]Processing batches:  14%|█▍        | 52/374 [04:17<22:33,  4.20s/it]Processing batches:  14%|█▍        | 53/374 [04:21<22:14,  4.16s/it]Processing batches:  14%|█▍        | 54/374 [04:22<17:24,  3.27s/it]Processing batches:  15%|█▍        | 55/374 [04:23<13:46,  2.59s/it]Processing batches:  15%|█▍        | 56/374 [04:27<15:40,  2.96s/it]Processing batches:  15%|█▌        | 57/374 [04:32<18:56,  3.59s/it]Processing batches:  16%|█▌        | 58/374 [04:34<16:39,  3.16s/it]Processing batches:  16%|█▌        | 59/374 [04:37<16:02,  3.06s/it]Processing batches:  16%|█▌        | 60/374 [04:39<13:41,  2.62s/it]Processing batches:  16%|█▋        | 61/374 [04:41<12:52,  2.47s/it]Processing batches:  17%|█▋        | 62/374 [04:43<13:06,  2.52s/it]Processing batches:  17%|█▋        | 63/374 [04:45<11:37,  2.24s/it]Processing batches:  17%|█▋        | 64/374 [04:46<10:30,  2.03s/it]Processing batches:  17%|█▋        | 65/374 [04:49<11:52,  2.31s/it]Processing batches:  18%|█▊        | 66/374 [04:51<10:55,  2.13s/it]Processing batches:  18%|█▊        | 67/374 [04:53<11:16,  2.20s/it]Processing batches:  18%|█▊        | 68/374 [04:55<10:40,  2.09s/it]Processing batches:  18%|█▊        | 69/374 [04:57<09:19,  1.83s/it]Processing batches:  19%|█▊        | 70/374 [04:58<08:29,  1.68s/it]Processing batches:  19%|█▉        | 71/374 [05:00<08:57,  1.78s/it]Processing batches:  19%|█▉        | 72/374 [05:02<08:52,  1.76s/it]Processing batches:  20%|█▉        | 73/374 [05:05<11:20,  2.26s/it]Processing batches:  20%|█▉        | 74/374 [05:08<12:02,  2.41s/it]Processing batches:  20%|██        | 75/374 [05:12<14:22,  2.88s/it]Processing batches:  20%|██        | 76/374 [05:15<15:06,  3.04s/it]Processing batches:  21%|██        | 77/374 [05:19<16:25,  3.32s/it]Processing batches:  21%|██        | 78/374 [05:23<16:45,  3.40s/it]Processing batches:  21%|██        | 79/374 [05:28<19:02,  3.87s/it]Processing batches:  21%|██▏       | 80/374 [05:32<19:11,  3.92s/it]Processing batches:  22%|██▏       | 81/374 [05:35<18:53,  3.87s/it]Processing batches:  22%|██▏       | 82/374 [05:39<18:15,  3.75s/it]Processing batches:  22%|██▏       | 83/374 [05:42<17:45,  3.66s/it]Processing batches:  22%|██▏       | 84/374 [05:46<18:18,  3.79s/it]Processing batches:  23%|██▎       | 85/374 [05:51<19:25,  4.03s/it]Processing batches:  23%|██▎       | 86/374 [05:56<20:13,  4.21s/it]Processing batches:  23%|██▎       | 87/374 [06:01<21:20,  4.46s/it]Processing batches:  24%|██▎       | 88/374 [06:06<21:47,  4.57s/it]Processing batches:  24%|██▍       | 89/374 [06:10<21:34,  4.54s/it]Processing batches:  24%|██▍       | 90/374 [06:14<21:16,  4.50s/it]Processing batches:  24%|██▍       | 91/374 [06:16<17:31,  3.72s/it]Processing batches:  25%|██▍       | 92/374 [06:18<14:40,  3.12s/it]Processing batches:  25%|██▍       | 93/374 [06:20<12:30,  2.67s/it]Processing batches:  25%|██▌       | 94/374 [06:23<12:52,  2.76s/it]Processing batches:  25%|██▌       | 95/374 [06:26<14:11,  3.05s/it]Processing batches:  26%|██▌       | 96/374 [06:29<12:54,  2.78s/it]Processing batches:  26%|██▌       | 97/374 [06:33<15:01,  3.25s/it]Processing batches:  26%|██▌       | 98/374 [06:38<17:23,  3.78s/it]Processing batches:  26%|██▋       | 99/374 [06:42<17:56,  3.92s/it]Processing batches:  27%|██▋       | 100/374 [06:46<17:16,  3.78s/it]Processing batches:  27%|██▋       | 101/374 [06:50<18:06,  3.98s/it]Processing batches:  27%|██▋       | 102/374 [06:53<16:53,  3.73s/it]Processing batches:  28%|██▊       | 103/374 [06:57<16:58,  3.76s/it]Processing batches:  28%|██▊       | 104/374 [07:01<17:01,  3.78s/it]Processing batches:  28%|██▊       | 105/374 [07:05<17:19,  3.87s/it]Processing batches:  28%|██▊       | 106/374 [07:09<17:14,  3.86s/it]Processing batches:  29%|██▊       | 107/374 [07:12<16:33,  3.72s/it]Processing batches:  29%|██▉       | 108/374 [07:16<16:41,  3.77s/it]Processing batches:  29%|██▉       | 109/374 [07:20<16:42,  3.78s/it]Processing batches:  29%|██▉       | 110/374 [07:24<16:36,  3.77s/it]Processing batches:  30%|██▉       | 111/374 [07:28<17:04,  3.90s/it]Processing batches:  30%|██▉       | 112/374 [07:32<16:56,  3.88s/it]Processing batches:  30%|███       | 113/374 [07:35<16:31,  3.80s/it]Processing batches:  30%|███       | 114/374 [07:39<16:46,  3.87s/it]Processing batches:  31%|███       | 115/374 [07:43<16:50,  3.90s/it]Processing batches:  31%|███       | 116/374 [07:47<16:06,  3.75s/it]Processing batches:  31%|███▏      | 117/374 [07:50<15:45,  3.68s/it]Processing batches:  32%|███▏      | 118/374 [07:53<14:56,  3.50s/it]Processing batches:  32%|███▏      | 119/374 [07:57<15:02,  3.54s/it]Processing batches:  32%|███▏      | 120/374 [08:00<14:40,  3.47s/it]Processing batches:  32%|███▏      | 121/374 [08:04<14:39,  3.48s/it]Processing batches:  33%|███▎      | 122/374 [08:07<14:51,  3.54s/it]Processing batches:  33%|███▎      | 123/374 [08:10<13:10,  3.15s/it]Processing batches:  33%|███▎      | 124/374 [08:13<13:56,  3.35s/it]Processing batches:  33%|███▎      | 125/374 [08:17<14:28,  3.49s/it]Processing batches:  34%|███▎      | 126/374 [08:21<14:30,  3.51s/it]Processing batches:  34%|███▍      | 127/374 [08:25<15:02,  3.65s/it]Processing batches:  34%|███▍      | 128/374 [08:27<13:43,  3.35s/it]Processing batches:  34%|███▍      | 129/374 [08:30<13:14,  3.24s/it]Processing batches:  35%|███▍      | 130/374 [08:34<13:05,  3.22s/it]Processing batches:  35%|███▌      | 131/374 [08:37<12:45,  3.15s/it]Processing batches:  35%|███▌      | 132/374 [08:40<12:48,  3.17s/it]Processing batches:  36%|███▌      | 133/374 [08:43<12:17,  3.06s/it]Processing batches:  36%|███▌      | 134/374 [08:45<11:56,  2.98s/it]Processing batches:  36%|███▌      | 135/374 [08:48<11:29,  2.88s/it]Processing batches:  36%|███▋      | 136/374 [08:51<11:20,  2.86s/it]Processing batches:  37%|███▋      | 137/374 [08:53<11:00,  2.79s/it]Processing batches:  37%|███▋      | 138/374 [08:56<11:02,  2.81s/it]Processing batches:  37%|███▋      | 139/374 [08:59<10:45,  2.75s/it]Processing batches:  37%|███▋      | 140/374 [09:01<10:32,  2.70s/it]Processing batches:  38%|███▊      | 141/374 [09:04<10:36,  2.73s/it]Processing batches:  38%|███▊      | 142/374 [09:07<10:32,  2.72s/it]Processing batches:  38%|███▊      | 143/374 [09:10<10:46,  2.80s/it]Processing batches:  39%|███▊      | 144/374 [09:14<11:45,  3.07s/it]Processing batches:  39%|███▉      | 145/374 [09:17<11:55,  3.12s/it]Processing batches:  39%|███▉      | 146/374 [09:20<11:38,  3.06s/it]Processing batches:  39%|███▉      | 147/374 [09:24<13:12,  3.49s/it]Processing batches:  40%|███▉      | 148/374 [09:28<12:49,  3.41s/it]Processing batches:  40%|███▉      | 149/374 [09:31<13:01,  3.47s/it]Processing batches:  40%|████      | 150/374 [09:34<12:21,  3.31s/it]Processing batches:  40%|████      | 151/374 [09:37<11:18,  3.04s/it]Processing batches:  41%|████      | 152/374 [09:39<10:33,  2.85s/it]Processing batches:  41%|████      | 153/374 [09:41<09:36,  2.61s/it]Processing batches:  41%|████      | 154/374 [09:44<09:33,  2.61s/it]Processing batches:  41%|████▏     | 155/374 [09:46<09:25,  2.58s/it]Processing batches:  42%|████▏     | 156/374 [09:50<10:22,  2.86s/it]Processing batches:  42%|████▏     | 157/374 [09:52<09:54,  2.74s/it]Processing batches:  42%|████▏     | 158/374 [09:54<09:31,  2.65s/it]Processing batches:  43%|████▎     | 159/374 [09:56<08:46,  2.45s/it]Processing batches:  43%|████▎     | 160/374 [09:58<08:11,  2.30s/it]Processing batches:  43%|████▎     | 161/374 [10:01<07:59,  2.25s/it]Processing batches:  43%|████▎     | 162/374 [10:03<07:44,  2.19s/it]Processing batches:  44%|████▎     | 163/374 [10:05<08:24,  2.39s/it]Processing batches:  44%|████▍     | 164/374 [10:08<08:45,  2.50s/it]Processing batches:  44%|████▍     | 165/374 [10:11<08:39,  2.49s/it]Processing batches:  44%|████▍     | 166/374 [10:13<08:57,  2.59s/it]Processing batches:  45%|████▍     | 167/374 [10:16<09:05,  2.64s/it]Processing batches:  45%|████▍     | 168/374 [10:19<08:54,  2.59s/it]Processing batches:  45%|████▌     | 169/374 [10:21<08:17,  2.43s/it]Processing batches:  45%|████▌     | 170/374 [10:23<08:05,  2.38s/it]Processing batches:  46%|████▌     | 171/374 [10:25<07:56,  2.35s/it]Processing batches:  46%|████▌     | 172/374 [10:27<06:54,  2.05s/it]Processing batches:  46%|████▋     | 173/374 [10:28<05:56,  1.77s/it]Processing batches:  47%|████▋     | 174/374 [10:29<05:16,  1.58s/it]Processing batches:  47%|████▋     | 175/374 [10:31<06:10,  1.86s/it]Processing batches:  47%|████▋     | 176/374 [10:33<05:42,  1.73s/it]Processing batches:  47%|████▋     | 177/374 [10:35<06:27,  1.97s/it]Processing batches:  48%|████▊     | 178/374 [10:39<07:58,  2.44s/it]Processing batches:  48%|████▊     | 179/374 [10:43<09:09,  2.82s/it]Processing batches:  48%|████▊     | 180/374 [10:46<09:55,  3.07s/it]Processing batches:  48%|████▊     | 181/374 [10:51<11:00,  3.42s/it]Processing batches:  49%|████▊     | 182/374 [10:53<09:42,  3.03s/it]Processing batches:  49%|████▉     | 183/374 [10:55<09:27,  2.97s/it]Processing batches:  49%|████▉     | 184/374 [10:59<10:14,  3.23s/it]Processing batches:  49%|████▉     | 185/374 [11:03<10:31,  3.34s/it]Processing batches:  50%|████▉     | 186/374 [11:08<11:50,  3.78s/it]Processing batches:  50%|█████     | 187/374 [11:11<11:40,  3.75s/it]Processing batches:  50%|█████     | 188/374 [11:14<10:36,  3.42s/it]Processing batches:  51%|█████     | 189/374 [11:18<10:48,  3.51s/it]Processing batches:  51%|█████     | 190/374 [11:23<11:57,  3.90s/it]Processing batches:  51%|█████     | 191/374 [11:27<12:30,  4.10s/it]Processing batches:  51%|█████▏    | 192/374 [11:32<12:42,  4.19s/it]Processing batches:  52%|█████▏    | 193/374 [11:36<13:10,  4.37s/it]Processing batches:  52%|█████▏    | 194/374 [11:40<12:07,  4.04s/it]Processing batches:  52%|█████▏    | 195/374 [11:42<10:53,  3.65s/it]Processing batches:  52%|█████▏    | 196/374 [11:45<09:42,  3.27s/it]Processing batches:  53%|█████▎    | 197/374 [11:48<09:27,  3.21s/it]Processing batches:  53%|█████▎    | 198/374 [11:50<08:28,  2.89s/it]Processing batches:  53%|█████▎    | 199/374 [11:53<08:35,  2.94s/it]Processing batches:  53%|█████▎    | 200/374 [11:56<08:17,  2.86s/it]Processing batches:  54%|█████▎    | 201/374 [11:58<08:05,  2.81s/it]Processing batches:  54%|█████▍    | 202/374 [12:01<07:28,  2.61s/it]Processing batches:  54%|█████▍    | 203/374 [12:04<08:27,  2.97s/it]Processing batches:  55%|█████▍    | 204/374 [12:07<08:31,  3.01s/it]Processing batches:  55%|█████▍    | 205/374 [12:12<10:08,  3.60s/it]Processing batches:  55%|█████▌    | 206/374 [12:16<09:53,  3.53s/it]Processing batches:  55%|█████▌    | 207/374 [12:20<10:35,  3.81s/it]Processing batches:  56%|█████▌    | 208/374 [12:24<10:45,  3.89s/it]Processing batches:  56%|█████▌    | 209/374 [12:28<10:20,  3.76s/it]Processing batches:  56%|█████▌    | 210/374 [12:32<10:56,  4.00s/it]Processing batches:  56%|█████▋    | 211/374 [12:37<11:42,  4.31s/it]Processing batches:  57%|█████▋    | 212/374 [12:41<10:58,  4.06s/it]Processing batches:  57%|█████▋    | 213/374 [12:44<10:25,  3.88s/it]Processing batches:  57%|█████▋    | 214/374 [12:48<10:31,  3.94s/it]Processing batches:  57%|█████▋    | 215/374 [12:52<09:55,  3.74s/it]Processing batches:  58%|█████▊    | 216/374 [12:54<09:03,  3.44s/it]Processing batches:  58%|█████▊    | 217/374 [12:57<08:27,  3.23s/it]Processing batches:  58%|█████▊    | 218/374 [13:01<09:00,  3.46s/it]Processing batches:  59%|█████▊    | 219/374 [13:04<08:42,  3.37s/it]Processing batches:  59%|█████▉    | 220/374 [13:07<08:11,  3.19s/it]Processing batches:  59%|█████▉    | 221/374 [13:10<08:02,  3.15s/it]Processing batches:  59%|█████▉    | 222/374 [13:13<07:39,  3.03s/it]Processing batches:  60%|█████▉    | 223/374 [13:16<07:21,  2.92s/it]Processing batches:  60%|█████▉    | 224/374 [13:20<08:40,  3.47s/it]Processing batches:  60%|██████    | 225/374 [13:25<09:45,  3.93s/it]Processing batches:  60%|██████    | 226/374 [13:29<09:50,  3.99s/it]Processing batches:  61%|██████    | 227/374 [13:34<10:30,  4.29s/it]Processing batches:  61%|██████    | 228/374 [13:39<10:30,  4.32s/it]Processing batches:  61%|██████    | 229/374 [13:44<10:57,  4.53s/it]Processing batches:  61%|██████▏   | 230/374 [13:48<10:27,  4.36s/it]Processing batches:  62%|██████▏   | 231/374 [13:53<10:53,  4.57s/it]Processing batches:  62%|██████▏   | 232/374 [13:57<10:38,  4.49s/it]Processing batches:  62%|██████▏   | 233/374 [14:02<10:37,  4.52s/it]Processing batches:  63%|██████▎   | 234/374 [14:06<10:19,  4.43s/it]Processing batches:  63%|██████▎   | 235/374 [14:11<10:39,  4.60s/it]Processing batches:  63%|██████▎   | 236/374 [14:14<09:26,  4.10s/it]Processing batches:  63%|██████▎   | 237/374 [14:17<08:42,  3.81s/it]Processing batches:  64%|██████▎   | 238/374 [14:21<08:43,  3.85s/it]Processing batches:  64%|██████▍   | 239/374 [14:24<08:02,  3.57s/it]Processing batches:  64%|██████▍   | 240/374 [14:27<07:40,  3.44s/it]Processing batches:  64%|██████▍   | 241/374 [14:30<07:08,  3.22s/it]Processing batches:  65%|██████▍   | 242/374 [14:33<06:47,  3.08s/it]Processing batches:  65%|██████▍   | 243/374 [14:35<06:23,  2.92s/it]Processing batches:  65%|██████▌   | 244/374 [14:39<06:59,  3.23s/it]Processing batches:  66%|██████▌   | 245/374 [14:42<06:56,  3.23s/it]Processing batches:  66%|██████▌   | 246/374 [14:47<08:00,  3.75s/it]Processing batches:  66%|██████▌   | 247/374 [14:51<07:50,  3.70s/it]Processing batches:  66%|██████▋   | 248/374 [14:56<08:33,  4.08s/it]Processing batches:  67%|██████▋   | 249/374 [15:00<08:33,  4.11s/it]Processing batches:  67%|██████▋   | 250/374 [15:04<08:32,  4.13s/it]Processing batches:  67%|██████▋   | 251/374 [15:09<09:01,  4.40s/it]Processing batches:  67%|██████▋   | 252/374 [15:14<09:19,  4.59s/it]Processing batches:  68%|██████▊   | 253/374 [15:19<09:29,  4.71s/it]Processing batches:  68%|██████▊   | 254/374 [15:23<09:09,  4.58s/it]Processing batches:  68%|██████▊   | 255/374 [15:28<08:55,  4.50s/it]Processing batches:  68%|██████▊   | 256/374 [15:33<09:09,  4.66s/it]Processing batches:  69%|██████▊   | 257/374 [15:35<07:49,  4.01s/it]Processing batches:  69%|██████▉   | 258/374 [15:37<06:42,  3.47s/it]Processing batches:  69%|██████▉   | 259/374 [15:41<06:36,  3.45s/it]Processing batches:  70%|██████▉   | 260/374 [15:44<06:25,  3.38s/it]Processing batches:  70%|██████▉   | 261/374 [15:47<05:56,  3.15s/it]Processing batches:  70%|███████   | 262/374 [15:50<05:43,  3.06s/it]Processing batches:  70%|███████   | 263/374 [15:52<05:07,  2.77s/it]Processing batches:  71%|███████   | 264/374 [15:54<04:46,  2.60s/it]Processing batches:  71%|███████   | 265/374 [15:58<05:26,  2.99s/it]Processing batches:  71%|███████   | 266/374 [16:03<06:27,  3.59s/it]Processing batches:  71%|███████▏  | 267/374 [16:07<06:31,  3.66s/it]Processing batches:  72%|███████▏  | 268/374 [16:11<07:04,  4.01s/it]Processing batches:  72%|███████▏  | 269/374 [16:16<07:31,  4.30s/it]Processing batches:  72%|███████▏  | 270/374 [16:21<07:37,  4.40s/it]Processing batches:  72%|███████▏  | 271/374 [16:26<07:53,  4.59s/it]Processing batches:  73%|███████▎  | 272/374 [16:31<08:02,  4.73s/it]Processing batches:  73%|███████▎  | 273/374 [16:35<07:33,  4.49s/it]Processing batches:  73%|███████▎  | 274/374 [16:39<07:21,  4.42s/it]Processing batches:  74%|███████▎  | 275/374 [16:44<07:34,  4.59s/it]Processing batches:  74%|███████▍  | 276/374 [16:49<07:42,  4.72s/it]Processing batches:  74%|███████▍  | 277/374 [16:52<06:36,  4.09s/it]Processing batches:  74%|███████▍  | 278/374 [16:54<05:48,  3.63s/it]Processing batches:  75%|███████▍  | 279/374 [16:59<06:10,  3.90s/it]Processing batches:  75%|███████▍  | 280/374 [17:01<05:16,  3.37s/it]Processing batches:  75%|███████▌  | 281/374 [17:04<04:56,  3.19s/it]Processing batches:  75%|███████▌  | 282/374 [17:06<04:37,  3.01s/it]Processing batches:  76%|███████▌  | 283/374 [17:10<04:57,  3.27s/it]Processing batches:  76%|███████▌  | 284/374 [17:12<04:15,  2.84s/it]Processing batches:  76%|███████▌  | 285/374 [17:15<04:18,  2.91s/it]Processing batches:  76%|███████▋  | 286/374 [17:18<04:06,  2.80s/it]Processing batches:  77%|███████▋  | 287/374 [17:23<05:00,  3.45s/it]Processing batches:  77%|███████▋  | 288/374 [17:26<04:49,  3.36s/it]Processing batches:  77%|███████▋  | 289/374 [17:29<04:26,  3.14s/it]Processing batches:  78%|███████▊  | 290/374 [17:32<04:26,  3.17s/it]Processing batches:  78%|███████▊  | 291/374 [17:36<04:38,  3.35s/it]Processing batches:  78%|███████▊  | 292/374 [17:41<05:15,  3.85s/it]Processing batches:  78%|███████▊  | 293/374 [17:46<05:39,  4.19s/it]Processing batches:  79%|███████▊  | 294/374 [17:51<05:54,  4.43s/it]Processing batches:  79%|███████▉  | 295/374 [17:55<05:45,  4.37s/it]Processing batches:  79%|███████▉  | 296/374 [17:59<05:36,  4.31s/it]Processing batches:  79%|███████▉  | 297/374 [18:04<05:47,  4.51s/it]Processing batches:  80%|███████▉  | 298/374 [18:07<05:02,  3.98s/it]Processing batches:  80%|███████▉  | 299/374 [18:09<04:27,  3.57s/it]Processing batches:  80%|████████  | 300/374 [18:14<04:43,  3.83s/it]Processing batches:  80%|████████  | 301/374 [18:17<04:26,  3.65s/it]Processing batches:  81%|████████  | 302/374 [18:20<04:10,  3.47s/it]Processing batches:  81%|████████  | 303/374 [18:23<04:00,  3.39s/it]Processing batches:  81%|████████▏ | 304/374 [18:26<03:39,  3.14s/it]Processing batches:  82%|████████▏ | 305/374 [18:28<03:24,  2.96s/it]Processing batches:  82%|████████▏ | 306/374 [18:33<04:02,  3.56s/it]Processing batches:  82%|████████▏ | 307/374 [18:38<04:27,  3.99s/it]Processing batches:  82%|████████▏ | 308/374 [18:42<04:23,  4.00s/it]Processing batches:  83%|████████▎ | 309/374 [18:47<04:38,  4.28s/it]Processing batches:  83%|████████▎ | 310/374 [18:52<04:46,  4.48s/it]Processing batches:  83%|████████▎ | 311/374 [18:57<04:49,  4.60s/it]Processing batches:  83%|████████▎ | 312/374 [19:01<04:34,  4.43s/it]Processing batches:  84%|████████▎ | 313/374 [19:06<04:41,  4.62s/it]Processing batches:  84%|████████▍ | 314/374 [19:10<04:28,  4.48s/it]Processing batches:  84%|████████▍ | 315/374 [19:14<04:16,  4.34s/it]Processing batches:  84%|████████▍ | 316/374 [19:19<04:09,  4.29s/it]Processing batches:  85%|████████▍ | 317/374 [19:24<04:17,  4.51s/it]Processing batches:  85%|████████▌ | 318/374 [19:29<04:22,  4.68s/it]Processing batches:  85%|████████▌ | 319/374 [19:34<04:24,  4.81s/it]Processing batches:  86%|████████▌ | 320/374 [19:39<04:23,  4.88s/it]Processing batches:  86%|████████▌ | 321/374 [19:44<04:21,  4.93s/it]Processing batches:  86%|████████▌ | 322/374 [19:49<04:18,  4.97s/it]Processing batches:  86%|████████▋ | 323/374 [19:54<04:14,  5.00s/it]Processing batches:  87%|████████▋ | 324/374 [19:59<04:11,  5.02s/it]Processing batches:  87%|████████▋ | 325/374 [20:03<03:56,  4.83s/it]Processing batches:  87%|████████▋ | 326/374 [20:08<03:55,  4.90s/it]Processing batches:  87%|████████▋ | 327/374 [20:14<03:52,  4.95s/it]Processing batches:  88%|████████▊ | 328/374 [20:19<03:48,  4.97s/it]Processing batches:  88%|████████▊ | 329/374 [20:24<03:44,  4.99s/it]Processing batches:  88%|████████▊ | 330/374 [20:29<03:40,  5.00s/it]Processing batches:  89%|████████▊ | 331/374 [20:34<03:35,  5.01s/it]Processing batches:  89%|████████▉ | 332/374 [20:38<03:28,  4.96s/it]Processing batches:  89%|████████▉ | 333/374 [20:43<03:22,  4.93s/it]Processing batches:  89%|████████▉ | 334/374 [20:48<03:12,  4.81s/it]Processing batches:  90%|████████▉ | 335/374 [20:53<03:10,  4.88s/it]Processing batches:  90%|████████▉ | 336/374 [20:58<03:06,  4.92s/it]Processing batches:  90%|█████████ | 337/374 [21:03<02:59,  4.84s/it]Processing batches:  90%|█████████ | 338/374 [21:07<02:52,  4.80s/it]Processing batches:  91%|█████████ | 339/374 [21:12<02:50,  4.87s/it]Processing batches:  91%|█████████ | 340/374 [21:17<02:47,  4.92s/it]Processing batches:  91%|█████████ | 341/374 [21:22<02:43,  4.95s/it]Processing batches:  91%|█████████▏| 342/374 [21:27<02:39,  4.97s/it]Processing batches:  92%|█████████▏| 343/374 [21:32<02:27,  4.77s/it]Processing batches:  92%|█████████▏| 344/374 [21:36<02:17,  4.58s/it]Processing batches:  92%|█████████▏| 345/374 [21:41<02:16,  4.72s/it]Processing batches:  93%|█████████▎| 346/374 [21:45<02:11,  4.68s/it]Processing batches:  93%|█████████▎| 347/374 [21:51<02:09,  4.79s/it]Processing batches:  93%|█████████▎| 348/374 [21:56<02:06,  4.86s/it]Processing batches:  93%|█████████▎| 349/374 [22:00<01:56,  4.65s/it]Processing batches:  94%|█████████▎| 350/374 [22:04<01:47,  4.48s/it]Processing batches:  94%|█████████▍| 351/374 [22:09<01:46,  4.64s/it]Processing batches:  94%|█████████▍| 352/374 [22:13<01:38,  4.49s/it]Processing batches:  94%|█████████▍| 353/374 [22:17<01:32,  4.41s/it]Processing batches:  95%|█████████▍| 354/374 [22:22<01:31,  4.59s/it]Processing batches:  95%|█████████▍| 355/374 [22:26<01:23,  4.41s/it]Processing batches:  95%|█████████▌| 356/374 [22:31<01:22,  4.60s/it]Processing batches:  95%|█████████▌| 357/374 [22:36<01:18,  4.61s/it]Processing batches:  96%|█████████▌| 358/374 [22:41<01:15,  4.72s/it]Processing batches:  96%|█████████▌| 359/374 [22:45<01:09,  4.66s/it]Processing batches:  96%|█████████▋| 360/374 [22:50<01:03,  4.56s/it]Processing batches:  97%|█████████▋| 361/374 [22:53<00:54,  4.22s/it]Processing batches:  97%|█████████▋| 362/374 [22:58<00:51,  4.31s/it]Processing batches:  97%|█████████▋| 363/374 [23:02<00:47,  4.28s/it]Processing batches:  97%|█████████▋| 364/374 [23:06<00:43,  4.31s/it]Processing batches:  98%|█████████▊| 365/374 [23:10<00:37,  4.15s/it]Processing batches:  98%|█████████▊| 366/374 [23:15<00:34,  4.36s/it]Processing batches:  98%|█████████▊| 367/374 [23:19<00:29,  4.20s/it]Processing batches:  98%|█████████▊| 368/374 [23:23<00:25,  4.31s/it]Processing batches:  99%|█████████▊| 369/374 [23:28<00:22,  4.42s/it]Processing batches:  99%|█████████▉| 370/374 [23:31<00:15,  3.98s/it]Processing batches:  99%|█████████▉| 371/374 [23:34<00:11,  3.77s/it]Processing batches:  99%|█████████▉| 372/374 [23:38<00:07,  3.89s/it]Processing batches: 100%|█████████▉| 373/374 [23:42<00:03,  3.79s/it]Processing batches: 100%|██████████| 374/374 [23:47<00:00,  4.24s/it]Processing batches: 100%|██████████| 374/374 [23:47<00:00,  3.82s/it]
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 64314.95 examples/s]
alpacaeval-easy: 0.9000
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 75797.92 examples/s]
alpacaeval-hard: 0.9263
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 70693.31 examples/s]
alpacaeval-length: 0.7579
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 76267.04 examples/s]
donotanswer: 0.8382
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 43775.14 examples/s]
hep-cpp: 0.9451
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 73345.89 examples/s]
hep-go: 0.9207
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 56236.54 examples/s]
hep-java: 0.9207
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 72655.09 examples/s]
hep-js: 0.9634
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 68742.85 examples/s]
hep-python: 0.9512
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 72086.17 examples/s]
hep-rust: 0.9146
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 72460.40 examples/s]
llmbar-adver-GPTInst: 0.8261
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 75539.53 examples/s]
llmbar-adver-GPTOut: 0.8936
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 71451.38 examples/s]
llmbar-adver-manual: 0.7391
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 75175.77 examples/s]
llmbar-adver-neighbor: 0.8657
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 56269.40 examples/s]
llmbar-natural: 0.9300
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 74249.78 examples/s]
math-prm: 0.9441
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 61960.25 examples/s]
mt-bench-easy: 0.8929
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 75307.80 examples/s]
mt-bench-hard: 0.8649
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 72894.52 examples/s]
mt-bench-med: 0.9000
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 75476.23 examples/s]
refusals-dangerous: 0.8900
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 76586.15 examples/s]
refusals-offensive: 0.8900
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 83979.48 examples/s]
xstest-should-refuse: 0.9805
Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]Filter: 100%|██████████| 2985/2985 [00:00<00:00, 72994.39 examples/s]
xstest-should-respond: 0.8840

Section Scores: {'Chat': 0.8687150837988827, 'Chat Hard': 0.8618421052631579, 'Safety': 0.8972972972972973, 'Reasoning': 0.940023599061494}
Traceback (most recent call last):
  File "/mnt/nlpgridio3/data/anirudh2/main/rewardbench_eval.py", line 248, in <module>
    main()
  File "/mnt/nlpgridio3/data/anirudh2/main/rewardbench_eval.py", line 237, in main
    save_to_hub(
  File "/mnt/nlpgridio3/data/anirudh2/venv/lib/python3.12/site-packages/rewardbench/utils.py", line 112, in save_to_hub
    os.makedirs(dirname, exist_ok=True)  # redundant in Beaker code
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen os>", line 225, in makedirs
PermissionError: [Errno 13] Permission denied: '/output'
